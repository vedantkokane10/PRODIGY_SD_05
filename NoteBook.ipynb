{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "490407ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12a0524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "010574b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers for requests\n",
    "URL = 'https://www.amazon.in/s?k=playstation&crid=L285YXF77263&sprefix=playstati%2Caps%2C695&ref=nb_sb_ss_ts-doa-p_2_9'\n",
    "HEADERS = ({'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75a37a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = requests.get(URL,headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79b38d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ca9d01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage = requests.get(URL,headers=HEADERS)\n",
    "webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0224b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry attempt 1 - Service Unavailable. Retrying in 5 seconds...\n",
      "Retry attempt 2 - Service Unavailable. Retrying in 5 seconds...\n",
      "Retry attempt 3 - Service Unavailable. Retrying in 5 seconds...\n",
      "Retry attempt 4 - Service Unavailable. Retrying in 5 seconds...\n",
      "Retry attempt 5 - Service Unavailable. Retrying in 5 seconds...\n",
      "Retry attempt 6 - Service Unavailable. Retrying in 5 seconds...\n",
      "Request successful!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "max_retries = 10\n",
    "retry_delay = 5  # seconds\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    \n",
    "    if webpage.status_code == 200:\n",
    "        print(\"Request successful!\")\n",
    "        break\n",
    "    elif webpage.status_code == 503:\n",
    "        print(f\"Retry attempt {attempt + 1} - Service Unavailable. Retrying in {retry_delay} seconds...\")\n",
    "        time.sleep(retry_delay)\n",
    "    else:\n",
    "        print(f\"Error: {webpage.status_code}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "567fa003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title\n",
    "def getTitle(soup):\n",
    "    titleValue = \"\"\n",
    "    try:\n",
    "        title = soup.find(\"span\",attrs={\"id\": \"productTitle\"})\n",
    "        titleText = title.text\n",
    "        titleValue = titleText.strip()\n",
    "    except AttributeError:\n",
    "        titleValue = \"\"\n",
    "    \n",
    "    return titleValue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc4812c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrice(soup):\n",
    "    priceValue = \"\"\n",
    "    try:\n",
    "        price = soup.find(\"span\",attrs={\"class\": \"a-price-whole\"})\n",
    "        priceValue = price.text.strip()\n",
    "    except AttributeError:\n",
    "        priceValue = \"\"\n",
    "    \n",
    "    return priceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de5f9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating\n",
    "def getRating(soup):    \n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\t\n",
    "    rating = rating[:3]\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e43ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Your existing code for making the initial request\n",
    "    URL = 'https://www.amazon.in/s?k=playstation&crid=L285YXF77263&sprefix=playstati%2Caps%2C695&ref=nb_sb_ss_ts-doa-p_2_9'\n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "    # List of links (a - tag href)\n",
    "    \n",
    "    links = soup.find_all(\"a\", attrs={'class':\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"})\n",
    "    linksList = []\n",
    "    for link in links:\n",
    "            linksList.append(link.get('href'))\n",
    "    \n",
    "    dic = {'title':[], 'price':[], 'rating':[]}\n",
    "    \n",
    "    for link in linksList:\n",
    "        if not link.startswith(('http://', 'https://')):\n",
    "            link = 'https://www.amazon.in' + link\n",
    "        newPage = requests.get(link, headers=HEADERS)\n",
    "        newSoup = BeautifulSoup(newPage.content, 'html.parser')\n",
    "        dic['title'].append(getTitle(newSoup))\n",
    "        dic['price'].append(getPrice(newSoup))\n",
    "        dic['rating'].append(getRating(newSoup))\n",
    "\n",
    "                         \n",
    "                         \n",
    "    df = pd.DataFrame.from_dict(dic)\n",
    "    df['title'].replace('',np.nan,inplace=True)\n",
    "    df = df.dropna(subset=['title'])\n",
    "    df.to_csv(\"EcommerceDataset.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68dfae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
